# ETL-magic

### Projeto ETL para T√©cnicas de Integra√ß√£o de Sistemas

Projeto de pipeline ETL desenvolvido para a disciplina de T√©cnicas de Integra√ß√£o de Sistemas. O objetivo √© implementar um pipeline completo de extra√ß√£o, transforma√ß√£o e carga usando uma base de dados p√∫blica (a API do Scryfall - Magic: The Gathering).

O projeto segue a arquitetura Medallion, organizando o armazenamento em tr√™s camadas de dados: Bronze, Silver e Gold.

üìú Relat√≥rio do Processo ETL
Esta se√ß√£o documenta o processo de desenvolvimento, conforme solicitado nas instru√ß√µes do trabalho.

1. Fonte dos Dados e Justificativa da Escolha

Fonte: Scryfall API

Justificativa: A Scryfall API √© uma base de dados p√∫blica de livre acesso, robusta e muito bem documentada, que fornece dados complexos sobre o card game Magic: The Gathering. Ela foi escolhida por:

- Riqueza de Dados: Cada "carta" √© um registro com dezenas de atributos (custos, textos, tipos, poder, etc.).
- Desafio de Transforma√ß√£o: Os dados v√™m em JSON aninhado, com campos polim√≥rficos (ex: cartas que n√£o s√£o criaturas n√£o t√™m power/toughness) e listas, o que torna a etapa de transforma√ß√£o (Silver) interessante.
- Formato Aberto: A API serve os dados em JSON, um dos formatos abertos sugeridos.

2. Estrutura e Formato dos Dados Originais

Formato: JSON.

Estrutura: A API (no endpoint `/cards/search`) retorna um objeto JSON paginado. O campo `data` cont√©m uma lista de objetos, onde cada objeto representa uma carta.

Camada Bronze: Os dados brutos (a lista extra√≠da do campo `data`) s√£o salvos sem qualquer modifica√ß√£o no arquivo `bronze/raw_cards.json`. Um exemplo de um objeto de carta (simplificado) √©:

```json
{
	"id": "000001a1-0000-0000-0000-000000000001",
	"name": "Anjo Serra",
	"mana_cost": "{3}{W}{W}",
	"cmc": 5.0,
	"type_line": "Creature ‚Äî Angel",
	"oracle_text": "Flying, vigilance",
	"power": "4",
	"toughness": "4",
	"rarity": "uncommon",
	"set": "mh3",
	"artist": "Mark Poole"
	// ... e dezenas de outros campos
}
```

3. Etapas de Transforma√ß√£o Aplicadas

O pipeline √© dividido em duas grandes etapas de transforma√ß√£o:

A. Bronze ‚ûî Silver (Limpeza e Normaliza√ß√£o)

Nesta fase, lemos o `bronze/raw_cards.json` e aplicamos as seguintes transforma√ß√µes para gerar uma tabela limpa:

- Carregamento: O JSON bruto √© carregado em um DataFrame pandas.
- Sele√ß√£o de Colunas: Apenas as colunas de interesse s√£o mantidas (ex: id, name, mana_cost, cmc, type_line, oracle_text, power, toughness, rarity, set, artist).
- Tratamento de Nulos: Campos que podem estar ausentes (como power, toughness em cartas que n√£o s√£o criaturas, ou mana_cost em terrenos) s√£o preenchidos com o valor padr√£o `'N/A'`.
- Engenharia de Features (Enriquecimento): A coluna `type_line` (ex: "Creature ‚Äî Eldrazi") √© dividida em duas novas colunas: `tipo_principal` ("Creature") e `subtipo` ("Eldrazi").
- Padroniza√ß√£o: A coluna `cmc` (custo de mana convertido) √© garantida como um tipo num√©rico.

Sa√≠da: O DataFrame limpo √© salvo em formato aberto CSV, em `silver/refined_cards.csv`.

B. Silver ‚ûî Gold (Agrega√ß√£o e Carga)

Nesta fase, lemos o `silver/refined_cards.csv` para criar o Data Warehouse final, pronto para an√°lise:

- Carregamento: O CSV limpo √© lido para um novo DataFrame.
- Cria√ß√£o de Agrega√ß√µes: Uma nova tabela (Fato) √© criada. N√≥s agrupamos os dados por `colecao`, `raridade` e `tipo_principal` e calculamos agrega√ß√µes, como a `contagem_cartas` e o `custo_medio_mana`.
- Carga no DW: O banco de dados SQLite (`gold/magic_data_warehouse.db`) √© criado e duas tabelas s√£o carregadas.

4. Modelo de Dados Final da Camada Gold

O Data Warehouse (`magic_data_warehouse.db`) representa o conjunto final de dados prontos para an√°lise. Ele cont√©m duas tabelas, seguindo um modelo dimensional simples:

dim_cartas (Tabela de Dimens√£o):

Cont√©m os dados limpos da camada Silver (uma linha por carta).

Colunas: `id`, `nome`, `custo_mana`, `custo_convertido`, `poder`, `resistencia`, `raridade`, `artista`, `tipo_principal`, `subtipo`, etc.

fact_resumo_colecao (Tabela de Fatos):

Cont√©m os dados agregados, prontos para BI/An√°lise.

Colunas: `colecao`, `raridade`, `tipo_principal`, `contagem_cartas`, `custo_medio_mana`.

5. Desafios Encontrados e Solu√ß√µes Adotadas

Desafio (Extra√ß√£o): A API da Scryfall implementa pagina√ß√£o. Uma √∫nica chamada n√£o retorna todas as cartas de uma cole√ß√£o, apenas os 175 primeiros resultados.

Solu√ß√£o: O script de extra√ß√£o (`extrair_dados_scryfall`) foi implementado com um loop `while`. Ele verifica o campo `has_more` na resposta da API e, se for `True`, faz uma nova requisi√ß√£o para a URL fornecida no campo `next_page`, acumulando os resultados at√© que todos os dados sejam baixados.

Desafio (Transforma√ß√£o): Os dados s√£o polim√≥rficos. Cartas de "Terreno", por exemplo, n√£o possuem `mana_cost` ou `power`. Isso gera dados nulos (`None` ou `NaN`) que quebram a carga no banco de dados.

Solu√ß√£o: Na etapa Silver, usamos `pandas.fillna('N/A')` para padronizar todos os campos textuais ausentes e `fillna(0)` para campos num√©ricos (como `cmc`), garantindo que o esquema da tabela final seja consistente e robusto.

Desafio (Ambiente): Garantir que o pipeline rode em qualquer m√°quina, independente das vers√µes de Python ou bibliotecas instaladas localmente.

Solu√ß√£o: O projeto inclui um `requirements.txt` para ambientes virtuais e um `Dockerfile` que "empacota" o script e suas depend√™ncias (pandas, requests, sqlalchemy), permitindo a execu√ß√£o isolada e reprodut√≠vel com um √∫nico comando Docker.

‚öôÔ∏è Instru√ß√µes de Execu√ß√£o do Pipeline
Estrutura do reposit√≥rio

```
Dockerfile
etl_magic.py          # Script principal com pipelines Bronze / Silver / Gold
requirements.txt      # Depend√™ncias do projeto
README.md             # Este arquivo (Relat√≥rio)
bronze/               # (Gerado) Sa√≠da da camada Bronze
silver/               # (Gerado) Sa√≠da da camada Silver
gold/                 # (Gerado) Sa√≠da da camada Gold
```

Pr√©-requisitos

- Python 3.8+
- (Opcional) Docker

Instala√ß√£o Local (virtualenv recomendado)
No PowerShell (Windows):

```powershell
# criar e ativar venv
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# instalar depend√™ncias
pip install -r requirements.txt
```

Como Usar
O script `etl_magic.py` executa as tr√™s camadas em sequ√™ncia.

```powershell
python etl_magic.py
```

Isso ir√° popular as pastas `bronze/`, `silver/` e `gold/` com seus respectivos artefatos.

Personaliza√ß√£o: Para alterar a cole√ß√£o (set) do Magic a ser baixada, altere a vari√°vel `SET_CODE = 'mh3'` dentro do `etl_magic.py`.

Uso com Docker (Recomendado)
O Docker executa o pipeline em um ambiente controlado.

1. Construir a Imagem: (Execute no terminal, na pasta do projeto)

```powershell
docker build -t meu-etl-magic .
```

2. Executar o Container: Este comando executa o pipeline e usa um "volume" (-v) para que os arquivos gerados (nas pastas `bronze/`, `silver/`, `gold/`) apare√ßam na sua m√°quina local.

```powershell
# Para PowerShell no Windows
docker run -v "${PWD}:/app" meu-etl-magic

# Para Linux / Mac / Git Bash
docker run -v "$(pwd):/app" meu-etl-magic
```


